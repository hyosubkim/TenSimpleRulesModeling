{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_M1random_v1(T, mu, b):\n",
    "    \n",
    "    # preallocate arrays pythonically ('a' ~ choice selection; 'r' ~ reward)\n",
    "    a = [0]*T\n",
    "    r = [0]*T\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # compute choice probabilities\n",
    "        p = np.array([b, 1-b])\n",
    "        \n",
    "        # make choice according to choice probabilities\n",
    "        #a.append(choose(p));\n",
    "        a[t] = choose(p);\n",
    "       \n",
    "        # generate reward based on choice\n",
    "        #r.append(np.random.uniform() < mu[a])\n",
    "        r[t] = np.random.uniform() < mu[a[t]]\n",
    "        \n",
    "    return a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose(p):\n",
    "    a = max(np.flatnonzero(np.append(-np.spacing(1), np.cumsum(p)) < np.random.uniform()))\n",
    "    #print(a)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "mu = np.array([0.2, 0.8])\n",
    "b = 0.5\n",
    "a, r = simulate_M1random_v1(T, mu, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(a)/len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros(100)\n",
    "for i in range(0,len(z)):\n",
    "    z[i] = np.random.uniform() < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.nan\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "epsilon/2 * np.array([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_M2WSLS_v1(T, mu, epsilon):\n",
    "    \n",
    "    a = [0]*T\n",
    "    r = [0]*T\n",
    "    \n",
    "    # initialize last reward/action with nan\n",
    "    rLast = np.nan\n",
    "    aLast = np.nan\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # compute choice probabilites\n",
    "        if np.isnan(rLast):\n",
    "            \n",
    "            # first trial choose randomly\n",
    "            p = np.array([0.5, 0.5])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # choice depends on last reward\n",
    "            if rLast == 1:\n",
    "                \n",
    "                # win stay (with probability 1-epsilon)\n",
    "                p = epsilon/2 * np.array([1, 1])\n",
    "                p[aLast] = 1 - epsilon / 2\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # lost shift (with probability 1-epsilon)\n",
    "                p = (1-epsilon/2) * np.array([1, 1])\n",
    "                p[aLast] = epsilon / 2\n",
    "                \n",
    "        # make choice according to choice probabilities\n",
    "        a[t] = choose(p)\n",
    "        \n",
    "        # generate reward based on choice\n",
    "        r[t] = np.random.uniform() < mu[a[t]]\n",
    "        \n",
    "        aLast = a[t]\n",
    "        rLast = r[t]\n",
    "        \n",
    "    return a, r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1\n",
    "a, r = simulate_M2WSLS_v1(T, mu, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_M3RescorlaWagner_v1(T, mu, alpha, beta):\n",
    "    \n",
    "    a = [0]*T\n",
    "    r = [0]*T\n",
    "    \n",
    "    Q = np.array([0.5, 0.5])\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # compute choice probabilities\n",
    "        p = np.exp(beta * Q) / np.sum(np.exp(beta * Q))\n",
    "        #p = math.exp()\n",
    "                                               \n",
    "        # make choice according to choice probabilities\n",
    "        a[t] = choose(p)\n",
    "        \n",
    "        # generate reward based on choice\n",
    "        r[t] = np.random.uniform() < mu[a[t]]\n",
    "        \n",
    "        # update values\n",
    "        delta = r[t] - Q[a[t]]\n",
    "        Q[a[t]] = Q[a[t]] + alpha * delta\n",
    "        \n",
    "    return a, r\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = 5\n",
    "a, r = simulate_M3RescorlaWagner_v1(T, mu, alpha, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([0.5, 0.5])\n",
    "beta = 5\n",
    "np.exp(beta * Q) / np.sum(np.exp(beta * Q))\n",
    "np.exp([beta * Q]) / np.sum(np.exp([beta * Q]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_M4ChoiceKernel_v1(T, mu, alpha_c, beta_c):\n",
    "    \n",
    "    CK = np.array([0, 0])\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # compute choice probabilities\n",
    "        p = np.exp(beta_c * CK) / np.sum(np.exp(beta_c * CK))\n",
    "        \n",
    "        # make choice according to choice probabilities\n",
    "        a[t] = choose(p)\n",
    "        \n",
    "        # generate reward based on choice\n",
    "        r[t] = np.random.uniform() < mu[a[t]]\n",
    "        \n",
    "        # update choice kernel\n",
    "        CK = (1-alpha_c) * CK\n",
    "        CK[a[t]] = CK[a[t]] + alpha_c * 1\n",
    "        \n",
    "    return a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_c = 0.1\n",
    "beta_c = 3\n",
    "a, r = simulate_M4ChoiceKernel_v1(T, mu, alpha_c, beta_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_M5RWCK_v1(T, mu, alpha, beta, alpha_c, beta_c):\n",
    "    \n",
    "    Q = np.array([0.5, 0.5])\n",
    "    CK = np.array([0, 0])\n",
    "    \n",
    "    for t in range(T):\n",
    "        \n",
    "        # compute choice probabilities\n",
    "        V = beta * Q + beta_c * CK\n",
    "        p = np.exp(V) / np.sum(np.exp(V))\n",
    "        \n",
    "        # make choice according to choice probabilities\n",
    "        a[t] = choose(p)\n",
    "        \n",
    "        # generate reward based on choice\n",
    "        r[t] = np.random.uniform() < mu[a[t]]\n",
    "        \n",
    "        # update values\n",
    "        delta = r[t] - Q[a[t]]\n",
    "        Q[a[t]] = Q[a[t]] + alpha * delta\n",
    "        \n",
    "        # update choice kernel\n",
    "        CK = (1-alpha_c) * CK\n",
    "        CK[a[t]] = CK[a[t]] + alpha_c * 1\n",
    "        \n",
    "    return a, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = 5\n",
    "alpha_c = 0.1\n",
    "beta_c = 1\n",
    "\n",
    "a, r = simulate_M5RWCK_v1(T, mu, alpha, beta, alpha_c, beta_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# experiment parameters\n",
    "T = 100\n",
    "mu = np.array([0.2, 0.8])\n",
    "\n",
    "# number of repetitions for simulations\n",
    "Nrep = 110\n",
    "sim = [{'a': np.zeros((T, Nrep)), 'r': np.zeros((T, Nrep)), 'wsls': np.zeros((2, Nrep))},{'a': np.zeros((T, Nrep)), 'r': np.zeros((T, Nrep)), 'wsls': np.zeros((2, Nrep))},{'a': np.zeros((T, Nrep)), 'r': np.zeros((T, Nrep)), 'wsls': np.zeros((2, Nrep))},{'a': np.zeros((T, Nrep)), 'r': np.zeros((T, Nrep)), 'wsls': np.zeros((2, Nrep))},{'a': np.zeros((T, Nrep)), 'r': np.zeros((T, Nrep)), 'wsls': np.zeros((2, Nrep))}]\n",
    "\n",
    "# Model 1: Random responding\n",
    "for n in range(Nrep):\n",
    "    b = 0.5\n",
    "    a, r = simulate_M1random_v1(T, mu, b)\n",
    "    sim[0]['a'][:, n] = a\n",
    "    sim[0]['r'][:, n] = r\n",
    "    \n",
    "# Model 2: Win-stay-lose-shift\n",
    "for n in range(Nrep):\n",
    "    epsilon = 0.1\n",
    "    a, r = simulate_M2WSLS_v1(T, mu, epsilon)\n",
    "    sim[1]['a'][:, n] = a\n",
    "    sim[1]['r'][:, n] = r\n",
    "\n",
    "# Model 3: Rescorla Wagner\n",
    "for n in range(Nrep):\n",
    "    alpha = 0.1\n",
    "    beta = 5\n",
    "    a, r = simulate_M3RescorlaWagner_v1(T, mu, alpha, beta)\n",
    "    sim[2]['a'][:, n] = a\n",
    "    sim[2]['r'][:, n] = r\n",
    "    \n",
    "# Model 4: Choice kernel\n",
    "for n in range(Nrep):\n",
    "    alpha_c = 0.1\n",
    "    beta_c = 3\n",
    "    a, r = simulate_M4ChoiceKernel_v1(T, mu, alpha_c, beta_c)\n",
    "    sim[3]['a'][:, n] = a\n",
    "    sim[3]['r'][:, n] = r\n",
    "\n",
    "# Model 5: Rescorla-Wagner + choice kernel\n",
    "for n in range(Nrep):\n",
    "    alpha = 0.1\n",
    "    beta = 5\n",
    "    alpha_c = 0.1\n",
    "    beta_c = 1\n",
    "    a, r = simulate_M5RWCK_v1(T, mu, alpha, beta, alpha_c, beta_c)\n",
    "    sim[4]['a'][:, n] = a\n",
    "    sim[4]['r'][:, n] = r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_WSLS_v1(a, r):\n",
    "    \n",
    "    aLast = np.append(np.nan, a[0:-1])\n",
    "    stay = aLast == a\n",
    "    rLast = np.append(np.nan, r[0:-1])\n",
    "                      \n",
    "    winStay = np.nanmean(stay[rLast == 1])\n",
    "    loseStay = np.nanmean(stay[rLast == 0])\n",
    "    out = np.array([loseStay, winStay])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# win-stay-lose-shift analysis\n",
    "wsls = np.zeros((2, len(sim)))\n",
    "for i in range(len(sim)):\n",
    "    for n in range(Nrep):\n",
    "        sim[i]['wsls'][:, n] = analysis_WSLS_v1(sim[i]['a'][:,n], sim[i]['r'][:, n])\n",
    "    wsls[:, i] = np.nanmean(sim[i]['wsls'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sim = [{'a': np.zeros((T, Nrep)), 'r': np.zeros((T, Nrep)), 'wsls': np.zeros((2, Nrep))}]*5\n",
    "np.nanmean(sim[2]['wsls'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot WSLS behavior for all models\n",
    "plt.figure()\n",
    "plt.plot([0, 1], wsls, '.-', markersize=20, linewidth=2)\n",
    "plt.ylim([0, 1])\n",
    "plt.legend([\"M1: random\", \"M2: WSLS\", \"M3: RW\", \"M4: CK\", \"M5: RW+CK\"])\n",
    "plt.xticks([0, 1])\n",
    "plt.xlabel('previous reward')\n",
    "plt.ylabel('probability of staying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p(correct) analysis\n",
    "alphas = np.array([0])\n",
    "np.linspace(0.02, 1.0, (1.0-0.02)/.02 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aLast = np.array([np.nan, a[0:-1]])\n",
    "np.shape(np.array([np.nan, a[0:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([1, 2, 3])\n",
    "np.append(np.nan, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sim)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsls = np.zeros((2, len(sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
